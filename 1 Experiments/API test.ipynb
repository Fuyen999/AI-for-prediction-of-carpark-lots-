{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pleased-african",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>backdrop_path</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>/nlCHUWjY9XWbuEUQauCBgnY8ymF.jpg</td>\n",
       "      <td>{'id': 8945, 'name': 'Mad Max Collection', 'po...</td>\n",
       "      <td>150000000</td>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 12, 'nam...</td>\n",
       "      <td>https://www.warnerbros.com/movies/mad-max-fury...</td>\n",
       "      <td>76341</td>\n",
       "      <td>tt1392190</td>\n",
       "      <td>en</td>\n",
       "      <td>Mad Max: Fury Road</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-05-13</td>\n",
       "      <td>378858340</td>\n",
       "      <td>121</td>\n",
       "      <td>[{'english_name': 'English', 'iso_639_1': 'en'...</td>\n",
       "      <td>Released</td>\n",
       "      <td>What a Lovely Day.</td>\n",
       "      <td>Mad Max: Fury Road</td>\n",
       "      <td>False</td>\n",
       "      <td>7.5</td>\n",
       "      <td>17649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                     backdrop_path  \\\n",
       "0  False  /nlCHUWjY9XWbuEUQauCBgnY8ymF.jpg   \n",
       "\n",
       "                               belongs_to_collection     budget  \\\n",
       "0  {'id': 8945, 'name': 'Mad Max Collection', 'po...  150000000   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 28, 'name': 'Action'}, {'id': 12, 'nam...   \n",
       "\n",
       "                                            homepage     id    imdb_id  \\\n",
       "0  https://www.warnerbros.com/movies/mad-max-fury...  76341  tt1392190   \n",
       "\n",
       "  original_language      original_title  ... release_date    revenue runtime  \\\n",
       "0                en  Mad Max: Fury Road  ...   2015-05-13  378858340     121   \n",
       "\n",
       "                                    spoken_languages    status  \\\n",
       "0  [{'english_name': 'English', 'iso_639_1': 'en'...  Released   \n",
       "\n",
       "              tagline               title  video vote_average vote_count  \n",
       "0  What a Lovely Day.  Mad Max: Fury Road  False          7.5      17649  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "key = \"472690ea187498e21bf4772871eb3df3\"\n",
    "url = \"https://api.themoviedb.org/3/movie/76341?api_key={}\".format(key)\n",
    "\n",
    "r = requests.get(url, auth=('user', 'pass'))\n",
    "with open(\"movie1.json\",\"w\") as movie1:\n",
    "    json.dump(r.json(), movie1)\n",
    "\n",
    "with open(\"movie1.json\") as movie1:\n",
    "    data = json.load(movie1)\n",
    "    \n",
    "Mad_max=pd.DataFrame.from_dict(data, orient='index').T\n",
    "Mad_max.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "executive-learning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 25 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   adult                  1 non-null      object\n",
      " 1   backdrop_path          1 non-null      object\n",
      " 2   belongs_to_collection  1 non-null      object\n",
      " 3   budget                 1 non-null      object\n",
      " 4   genres                 1 non-null      object\n",
      " 5   homepage               1 non-null      object\n",
      " 6   id                     1 non-null      object\n",
      " 7   imdb_id                1 non-null      object\n",
      " 8   original_language      1 non-null      object\n",
      " 9   original_title         1 non-null      object\n",
      " 10  overview               1 non-null      object\n",
      " 11  popularity             1 non-null      object\n",
      " 12  poster_path            1 non-null      object\n",
      " 13  production_companies   1 non-null      object\n",
      " 14  production_countries   1 non-null      object\n",
      " 15  release_date           1 non-null      object\n",
      " 16  revenue                1 non-null      object\n",
      " 17  runtime                1 non-null      object\n",
      " 18  spoken_languages       1 non-null      object\n",
      " 19  status                 1 non-null      object\n",
      " 20  tagline                1 non-null      object\n",
      " 21  title                  1 non-null      object\n",
      " 22  video                  1 non-null      object\n",
      " 23  vote_average           1 non-null      object\n",
      " 24  vote_count             1 non-null      object\n",
      "dtypes: object(25)\n",
      "memory usage: 328.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "Mad_max.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "external-consolidation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-24 00:47:24.401075\n",
      "http://files.tmdb.org/p/exports/movie_ids_02_24_2021.json.gz\n"
     ]
    },
    {
     "ename": "BadGzipFile",
     "evalue": "Not a gzipped file (b'<?')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadGzipFile\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-11a047b62cfc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0ms_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"movie_id.json\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0md_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m65536\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[1;34m(fsrc, fdst, length)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[0mfdst_write\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m         \u001b[0mbuf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfsrc_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\gzip.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"B\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\gzip.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    477\u001b[0m                 \u001b[1;31m# jump to the next member, if there is one.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_gzip_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    480\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[1;34mb\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\gzip.py\u001b[0m in \u001b[0;36m_read_gzip_header\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmagic\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34mb'\\037\\213'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mBadGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Not a gzipped file (%r)'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmagic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m         (method, flag,\n",
      "\u001b[1;31mBadGzipFile\u001b[0m: Not a gzipped file (b'<?')"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "\n",
    "print(datetime.utcnow())\n",
    "movie_id_url = \"http://files.tmdb.org/p/exports/movie_ids_{}.json.gz\".format(datetime.utcnow().strftime(\"%m_%d_%Y\"))\n",
    "print(movie_id_url)\n",
    "\n",
    "filename = movie_id_url.split(\"/\")[-1]\n",
    "with open(filename, \"wb\") as f:\n",
    "    movie_id = requests.get(movie_id_url)\n",
    "    f.write(movie_id.content)\n",
    "    \n",
    "import gzip\n",
    "import shutil\n",
    "with gzip.open(filename, 'rb') as s_file, open(\"movie_id.json\", 'wb') as d_file:\n",
    "    shutil.copyfileobj(s_file, d_file, 65536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"movie_id.json\", \"r\", encoding = \"utf-8\") as movie_id:\n",
    "    movies = pd.read_json(movie_id.readline(), orient=\"index\").T\n",
    "    \n",
    "    for i in range(0, 1000):\n",
    "        try:\n",
    "            with open(\"movie.json\", \"w\") as movie:\n",
    "                movie.write(movie_id.readline())\n",
    "        except:\n",
    "            continue\n",
    "        movies = movies.append(pd.read_json(movie_id.readline(), orient=\"index\").T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    #Authentication parameters\n",
    "    headers = { 'AccountKey' : '472690ea187498e21bf4772871eb3df3',\n",
    "                'accept' : 'application/json'} #this is by default\n",
    "    \n",
    "    #API parameters\n",
    "    uri = 'http://datamall2.mytransport.sg/' #Resource URL\n",
    "    path = 'ltaodataservice/BusArrivalv2?BusStopCode=83139'\n",
    "    \n",
    "    #Build query string & specify type of API call\n",
    "    target = urlparse(uri + path)\n",
    "    print(target.geturl())\n",
    "    method = 'GET'\n",
    "    body = ''\n",
    "\n",
    "    #Get handle to http\n",
    "    h = http.Http()\n",
    "\n",
    "    #Obtain results\n",
    "    response, content = h.request(target.geturl(),\n",
    "                                    method,\n",
    "                                    body,\n",
    "                                    headers)\n",
    "    #Parse JSON to print\n",
    "    jsonObj = json.loads(content)\n",
    "    print(json.dumps(jsonObj, sort_keys=True, indent=4))\n",
    "\n",
    "    #Save result to file|\n",
    "    with open(\"bus_routes.json\",\"w\") as outfile: #Saving jsonObj[\"d\"]\n",
    "        json.dump(jsonObj, outfile, sort_keys=True, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    #Authentication parameters\n",
    "    headers = { 'AccountKey' : '472690ea187498e21bf4772871eb3df3',\n",
    "                'accept' : 'application/json'} #this is by default\n",
    "    \n",
    "    #API parameters\n",
    "    uri = 'http://datamall2.mytransport.sg/' #Resource URL\n",
    "    path = 'ltaodataservice/BusArrivalv2?BusStopCode=83139'\n",
    "    \n",
    "    #Build query string & specify type of API call\n",
    "    target = urlparse(uri + path)\n",
    "    print(target.geturl())\n",
    "    method = 'GET'\n",
    "    body = ''\n",
    "\n",
    "    #Get handle to http\n",
    "    h = http.Http()\n",
    "\n",
    "    #Obtain results\n",
    "    response, content = h.request(target.geturl(),\n",
    "                                    method,\n",
    "                                    body,\n",
    "                                    headers)\n",
    "    #Parse JSON to print\n",
    "    jsonObj = json.loads(content)\n",
    "    print(json.dumps(jsonObj, sort_keys=True, indent=4))\n",
    "\n",
    "    #Save result to file|\n",
    "    with open(\"bus_routes.json\",\"w\") as outfile: #Saving jsonObj[\"d\"]\n",
    "        json.dump(jsonObj, outfile, sort_keys=True, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib\n",
    "from urllib.parse import urlparse\n",
    "import httplib2 as http #External library\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    #Authentication parameters\n",
    "    headers = { 'AccountKey' : 'opoOfz6bTza7BMCTCy8VFA==',\n",
    "                'accept' : 'application/json'} #this is by default\n",
    "    \n",
    "    #API parameters\n",
    "    uri = 'http://datamall2.mytransport.sg/' #Resource URL\n",
    "    path = 'ltaodataservice/BusArrivalv2?BusStopCode=83139'\n",
    "    \n",
    "    #Build query string & specify type of API call\n",
    "    target = urlparse(uri + path)\n",
    "    print(target.geturl())\n",
    "    method = 'GET'\n",
    "    body = ''\n",
    "\n",
    "    #Get handle to http\n",
    "    h = http.Http()\n",
    "\n",
    "    #Obtain results\n",
    "    response, content = h.request(target.geturl(),\n",
    "                                    method,\n",
    "                                    body,\n",
    "                                    headers)\n",
    "    #Parse JSON to print\n",
    "    jsonObj = json.loads(content)\n",
    "    print(json.dumps(jsonObj, sort_keys=True, indent=4))\n",
    "\n",
    "    #Save result to file|\n",
    "    with open(\"bus_routes.json\",\"w\") as outfile: #Saving jsonObj[\"d\"]\n",
    "        json.dump(jsonObj, outfile, sort_keys=True, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "busurl = 'http://datamall2.mytransport.sg/ltaodataservice/BusArrivalv2?BusStopCode=83139'\n",
    "headers = { 'AccountKey' : 'opoOfz6bTza7BMCTCy8VFA==',\n",
    "                'accept' : 'application/json'}\n",
    "bus = requests.get(busurl, headers=headers)\n",
    "\n",
    "bus.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-cheat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-timing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
